# TinyStories LLM Certificate Extraction & Subspace Analysis

This repository provides all code, data, and documentation necessary to reproduce the certificate-driven principal component analysis for TinyStories GPT-2 activations, as described in our paper.

## File List

- `tinystories_gpt2_activations.npy`: Raw GPT-2 mean-pooled last-layer activations for 100 TinyStories texts.
- `tinystories_texts.csv`: The corresponding 100 TinyStories texts.
- `llm_pca_components.npy`: First 50 PCA directions (orthonormal basis, shape (50, 768)).
- `llm_pca_mean.npy`: Mean activation vector (768,).
- `llm_pca_projections.npy`: Activations projected onto the first 50 PCs (100, 50).
- `llm_pca_explained_var.npy`: Variance explained by each of the first 50 PCs.
- `llm_pca_cumulative_variance.csv`: Cumulative variance explained by #PCs.
- `llm_principal_angles_deg.npy`: Principal angles (degrees) between subspaces of two random splits (top-9 PCs).
- `llm_pc_scatter.png`: 2D scatterplot of first two PCs.
- `stats_summary.json`: Basic statistics and certificate results (generated by script).

## Reproducing the Results

1. **Install dependencies**
    ```bash
    pip install numpy pandas matplotlib scikit-learn
    ```

2. **Run the analysis script**
    ```bash
    python make_certificates.py
    ```

3. **All outputs will be generated as above.**

## File Descriptions

- **tinystories_gpt2_activations.npy**: Raw model activations (numpy array).
- **tinystories_texts.csv**: The actual TinyStories texts.
- **llm_pca_components.npy**: Top-50 principal components (PCA directions).
- **llm_pca_mean.npy**: Mean for centering input.
- **llm_pca_projections.npy**: Each text's activation, projected onto the PCA basis.
- **llm_pca_explained_var.npy**: Variance explained by each PC.
- **llm_pca_cumulative_variance.csv**: Table of N PCs vs. total variance explained.
- **llm_principal_angles_deg.npy**: Principal angles between random splits (top-9 PCs).
- **llm_pc_scatter.png**: Visualization of the semantic geometry.
- **stats_summary.json**: Statistical summary (see below).

## Metadata

- Model: GPT-2 (small), Hugging Face transformers
- Dataset: TinyStories (Hugging Face, v1.1)
- Key libraries: numpy, pandas, matplotlib, scikit-learn (see requirements.txt for versions)

## Citation

If you use this code or data, please cite our paper and the TinyStories and HuggingFace repositories.
